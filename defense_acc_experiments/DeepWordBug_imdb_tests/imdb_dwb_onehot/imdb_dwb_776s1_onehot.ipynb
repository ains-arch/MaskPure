{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf45ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 22:16:15.192176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 22:16:16.368645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install --upgrade -tensorflow_hub\n",
    "# !pip install -U -huggingface_hub\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import textattack\n",
    "import transformers\n",
    "import torch\n",
    "import time\n",
    "from datasets import Dataset\n",
    "import sys\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForMaskedLM, pipeline\n",
    "from textattack.attack_recipes import (\n",
    "    TextBuggerLi2018, DeepWordBugGao2018, TextFoolerJin2019, BERTAttackLi2020\n",
    ")\n",
    "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "sys.path.append('../../')\n",
    "from eval_utils import *\n",
    "sys.path.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199d2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a device name to run on: cuda:0\n",
      "Enter the number of samples to run on (100 or 776): 776\n",
      "Specify a defense type among \"default\", \"logit\", \"maj_log\", \"one_hot\": one_hot\n",
      "Which section of the dataset would you like to load and test on? (1, 2, or 3): 1\n",
      "using num_voter = 11 and mask_pct = 0.3 with dataset = imdb776_1...\n",
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterSubstitution(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): LevenshteinEditDistance(\n",
      "        (max_edit_distance):  30\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 22 / 1 / 25:  10%|█         | 25/250 [4:35:58<41:23:46, 662.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 7 / 41 / 2 / 50:  20%|██        | 50/250 [8:46:16<35:05:07, 631.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 9 / 61 / 5 / 75:  30%|███       | 75/250 [13:10:32<30:44:36, 632.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 12 / 80 / 8 / 100:  40%|████      | 100/250 [18:31:11<27:46:47, 666.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 15 / 100 / 10 / 125:  50%|█████     | 125/250 [23:20:27<23:20:27, 672.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 18 / 120 / 12 / 150:  60%|██████    | 150/250 [28:32:04<19:01:22, 684.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 18 / 140 / 17 / 175:  70%|███████   | 175/250 [33:26:51<14:20:05, 688.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 21 / 162 / 17 / 200:  80%|████████  | 200/250 [39:41:39<9:55:24, 714.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 23 / 183 / 19 / 225:  90%|█████████ | 225/250 [43:59:25<4:53:16, 703.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 27 / 203 / 20 / 250: 100%|██████████| 250/250 [48:28:09<00:00, 697.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 27 / 203 / 20 / 250: 100%|██████████| 250/250 [48:28:09<00:00, 697.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 27     |\n",
      "| Number of failed attacks:     | 203    |\n",
      "| Number of skipped attacks:    | 20     |\n",
      "| Original accuracy:            | 92.0%  |\n",
      "| Accuracy under attack:        | 81.2%  |\n",
      "| Attack success rate:          | 11.74% |\n",
      "| Average perturbed word %:     | 0.77%  |\n",
      "| Average num. words per input: | 160.28 |\n",
      "| Avg num queries:              | 413.63 |\n",
      "+-------------------------------+--------+\n",
      "The above are results for DeepWordBugGao2018_imdb776_1_mp0.3_nv11_one_hot.\n"
     ]
    }
   ],
   "source": [
    "# set a seed, because reproducability is cool\n",
    "np.random.seed(int(hashlib.sha256('Harrison Gietz'.encode('utf-8')).hexdigest(), 16) % 2**32)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = input('enter a device name to run on: ')\n",
    "dataset_val = input('Enter the number of samples to run on (100 or 776): ')\n",
    "defense = input('Specify a defense type among \"default\", \"logit\", \"maj_log\", \"one_hot\": ')\n",
    "\n",
    "imdb_tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "imdb_model = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "imdb_model.to(device)\n",
    "imdb_pipeline = pipeline('sentiment-analysis', model=imdb_model, tokenizer=imdb_tokenizer)\n",
    "imdb_pipeline.device = next(imdb_model.parameters()).device\n",
    "\n",
    "imdb_model_directory = \"../../../../models/bert-uncased_maskedlm_imdb_july31_chk3\"\n",
    "finetuned_imdb_maskedlm = BertForMaskedLM.from_pretrained(imdb_model_directory)\n",
    "finetuned_imdb_maskedlm.to(device)\n",
    "imdb_fill_mask = pipeline(\"fill-mask\", model=finetuned_imdb_maskedlm, tokenizer=imdb_tokenizer)\n",
    "imdb_fill_mask.device = next(imdb_model.parameters()).device\n",
    "\n",
    "num_voter = 11\n",
    "mask_pct = 0.3    \n",
    "    \n",
    "attack = DeepWordBugGao2018\n",
    "\n",
    "if dataset_val == '100':\n",
    "    loaded_imdb_100 = Dataset.load_from_disk('../../data/filtered_imdb_clean_100')\n",
    "    imdb_100 = textattack.datasets.Dataset(convert_to_tuples(loaded_imdb_100))\n",
    "    dataset = imdb_100\n",
    "    dataset_name = 'imdb100'\n",
    "elif dataset_val =='776':\n",
    "    # because there were problems running epxeiremtns for days on end with the larger dataset,\n",
    "    # the 776 samples were split up into 250, 250, 276 (sections 1,2,3 respectively).\n",
    "    # hence experiments are run on each section separately, with final score coming from the collective results.\n",
    "    dataset_section = input('Which section of the dataset would you like to load and test on? (1, 2, or 3): ')\n",
    "    loaded_imdb_776 = Dataset.load_from_disk(f'../../data/filtered_imdb_clean_776_{dataset_section}')\n",
    "    imdb_776 = textattack.datasets.Dataset(convert_to_tuples(loaded_imdb_776))\n",
    "    dataset = imdb_776\n",
    "    dataset_name = f'imdb776_{dataset_section}'\n",
    "else:\n",
    "    raise ValueError('Number of samples not supported')\n",
    "    \n",
    "if defense == \"default\":\n",
    "    imdb_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(imdb_model, imdb_tokenizer)\n",
    "elif defense == \"logit\":\n",
    "    imdb_wrapper = MaskDemaskWrapper(imdb_model, imdb_tokenizer, imdb_fill_mask, num_voter, mask_pct, 'logit')\n",
    "elif defense == 'maj_log':\n",
    "    imdb_wrapper = MaskDemaskWrapper(imdb_model, imdb_tokenizer, imdb_fill_mask, num_voter, mask_pct, 'maj_log')\n",
    "elif defense == \"one_hot\":\n",
    "    imdb_wrapper = MaskDemaskWrapper(imdb_model, imdb_tokenizer, imdb_fill_mask, num_voter, mask_pct, 'maj_one_hot')\n",
    "else:\n",
    "    raise ValueError('Not a valid defense type.')\n",
    "\n",
    "print(f'using num_voter = {num_voter} and mask_pct = {mask_pct} with dataset = {dataset_name}...')\n",
    "\n",
    "# Parse the attack name\n",
    "attack_name = parse_attack_name(attack)\n",
    "attack = attack.build(imdb_wrapper)\n",
    "\n",
    "# Set up arguments for the attack\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=len(dataset),\n",
    "    log_to_csv=f'{attack_name}_{dataset_name}_mp{mask_pct}_nv{num_voter}_{defense}_log.csv',\n",
    "    checkpoint_interval=25, \n",
    "    checkpoint_dir=\"chkpts_2\", \n",
    "    disable_stdout=True\n",
    ")\n",
    "# Perform the attack and save the results\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "print(f'The above are results for {attack_name}_{dataset_name}_mp{mask_pct}_nv{num_voter}_{defense}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "89"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf45ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 22:15:41.689714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 22:15:42.902514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install --upgrade -tensorflow_hub\n",
    "# !pip install -U -huggingface_hub\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import textattack\n",
    "import transformers\n",
    "import torch\n",
    "import time\n",
    "from datasets import Dataset\n",
    "import sys\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertForMaskedLM, pipeline\n",
    "from textattack.attack_recipes import (\n",
    "    TextBuggerLi2018, DeepWordBugGao2018, TextFoolerJin2019, BERTAttackLi2020\n",
    ")\n",
    "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
    "from textattack.models.wrappers import ModelWrapper\n",
    "\n",
    "sys.path.append('../../')\n",
    "from eval_utils import *\n",
    "sys.path.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "199d2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a device name to run on: cuda:0\n",
      "Enter the number of samples to run on (100 or 776): 776\n",
      "Specify a defense type among \"default\", \"logit\", \"maj_log\", \"one_hot\": maj_log\n",
      "Which section of the dataset would you like to load and test on? (1, 2, or 3): 3\n",
      "using num_voter = 11 and mask_pct = 0.3 with dataset = imdb776_3...\n",
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  UntargetedClassification\n",
      "  (transformation):  CompositeTransformation(\n",
      "    (0): WordSwapNeighboringCharacterSwap(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (1): WordSwapRandomCharacterSubstitution(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (2): WordSwapRandomCharacterDeletion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    (3): WordSwapRandomCharacterInsertion(\n",
      "        (random_one):  True\n",
      "      )\n",
      "    )\n",
      "  (constraints): \n",
      "    (0): LevenshteinEditDistance(\n",
      "        (max_edit_distance):  30\n",
      "        (compare_against_original):  True\n",
      "      )\n",
      "    (1): RepeatModification\n",
      "    (2): StopwordModification\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/276 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "[Succeeded / Failed / Skipped / Total] 8 / 16 / 1 / 25:   9%|▉         | 25/276 [3:35:22<36:02:19, 516.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 13 / 34 / 3 / 50:  18%|█▊        | 50/276 [8:35:25<38:49:43, 618.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 14 / 57 / 4 / 75:  27%|██▋       | 75/276 [13:11:57<35:22:26, 633.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 26 / 69 / 5 / 100:  36%|███▌      | 100/276 [16:21:16<28:47:01, 588.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 33 / 83 / 9 / 125:  45%|████▌     | 125/276 [18:39:30<22:32:21, 537.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 40 / 99 / 11 / 150:  54%|█████▍    | 150/276 [21:56:13<18:25:37, 526.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 44 / 119 / 12 / 175:  63%|██████▎   | 175/276 [26:18:27<15:10:59, 541.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 51 / 134 / 15 / 200:  72%|███████▏  | 200/276 [29:01:59<11:01:57, 522.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 56 / 151 / 18 / 225:  82%|████████▏ | 225/276 [31:39:54<7:10:38, 506.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 61 / 169 / 20 / 250:  91%|█████████ | 250/276 [35:15:53<3:40:03, 507.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 65 / 190 / 20 / 275: 100%|█████████▉| 275/276 [38:53:09<08:29, 509.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================================================================================================================\n",
      "=============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 65 / 191 / 20 / 276: 100%|██████████| 276/276 [39:04:10<00:00, 509.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 65     |\n",
      "| Number of failed attacks:     | 191    |\n",
      "| Number of skipped attacks:    | 20     |\n",
      "| Original accuracy:            | 92.75% |\n",
      "| Accuracy under attack:        | 69.2%  |\n",
      "| Attack success rate:          | 25.39% |\n",
      "| Average perturbed word %:     | 2.28%  |\n",
      "| Average num. words per input: | 155.42 |\n",
      "| Avg num queries:              | 365.58 |\n",
      "+-------------------------------+--------+\n",
      "The above are results for DeepWordBugGao2018_imdb776_3_mp0.3_nv11_maj_log.\n"
     ]
    }
   ],
   "source": [
    "# set a seed, because reproducability is cool\n",
    "np.random.seed(int(hashlib.sha256('Harrison Gietz'.encode('utf-8')).hexdigest(), 16) % 2**32)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = input('enter a device name to run on: ')\n",
    "dataset_val = input('Enter the number of samples to run on (100 or 776): ')\n",
    "defense = input('Specify a defense type among \"default\", \"logit\", \"maj_log\", \"one_hot\": ')\n",
    "\n",
    "imdb_tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "imdb_model = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-imdb\")\n",
    "imdb_model.to(device)\n",
    "imdb_pipeline = pipeline('sentiment-analysis', model=imdb_model, tokenizer=imdb_tokenizer)\n",
    "imdb_pipeline.device = next(imdb_model.parameters()).device\n",
    "\n",
    "imdb_model_directory = \"../../../../models/bert-uncased_maskedlm_imdb_july31_chk3\"\n",
    "finetuned_imdb_maskedlm = BertForMaskedLM.from_pretrained(imdb_model_directory)\n",
    "finetuned_imdb_maskedlm.to(device)\n",
    "imdb_fill_mask = pipeline(\"fill-mask\", model=finetuned_imdb_maskedlm, tokenizer=imdb_tokenizer)\n",
    "imdb_fill_mask.device = next(imdb_model.parameters()).device\n",
    "\n",
    "num_voter = 11\n",
    "mask_pct = 0.3    \n",
    "    \n",
    "attack = DeepWordBugGao2018\n",
    "\n",
    "if dataset_val == '100':\n",
    "    loaded_imdb_100 = Dataset.load_from_disk('../../data/filtered_imdb_clean_100')\n",
    "    imdb_100 = textattack.datasets.Dataset(convert_to_tuples(loaded_imdb_100))\n",
    "    dataset = imdb_100\n",
    "    dataset_name = 'imdb100'\n",
    "elif dataset_val =='776':\n",
    "    # because there were problems running epxeiremtns for days on end with the larger dataset,\n",
    "    # the 776 samples were split up into 250, 250, 276 (sections 1,2,3 respectively).\n",
    "    # hence experiments are run on each section separately, with final score coming from the collective results.\n",
    "    dataset_section = input('Which section of the dataset would you like to load and test on? (1, 2, or 3): ')\n",
    "    loaded_imdb_776 = Dataset.load_from_disk(f'../../data/filtered_imdb_clean_776_{dataset_section}')\n",
    "    imdb_776 = textattack.datasets.Dataset(convert_to_tuples(loaded_imdb_776))\n",
    "    dataset = imdb_776\n",
    "    dataset_name = f'imdb776_{dataset_section}'\n",
    "else:\n",
    "    raise ValueError('Number of samples not supported')\n",
    "    \n",
    "if defense == \"default\":\n",
    "    imdb_wrapper = textattack.models.wrappers.HuggingFaceModelWrapper(imdb_model, imdb_tokenizer)\n",
    "elif defense == \"logit\":\n",
    "    imdb_wrapper = MaskDemaskWrapper(imdb_model, imdb_tokenizer, imdb_fill_mask, num_voter, mask_pct, 'logit')\n",
    "elif defense == 'maj_log':\n",
    "    imdb_wrapper = MaskDemaskWrapper(imdb_model, imdb_tokenizer, imdb_fill_mask, num_voter, mask_pct, 'maj_log')\n",
    "elif defense == \"one_hot\":\n",
    "    imdb_wrapper = MaskDemaskWrapper(imdb_model, imdb_tokenizer, imdb_fill_mask, num_voter, mask_pct, 'maj_one_hot')\n",
    "else:\n",
    "    raise ValueError('Not a valid defense type.')\n",
    "\n",
    "print(f'using num_voter = {num_voter} and mask_pct = {mask_pct} with dataset = {dataset_name}...')\n",
    "\n",
    "# Parse the attack name\n",
    "attack_name = parse_attack_name(attack)\n",
    "attack = attack.build(imdb_wrapper)\n",
    "\n",
    "# Set up arguments for the attack\n",
    "attack_args = textattack.AttackArgs(\n",
    "    num_examples=len(dataset),\n",
    "    log_to_csv=f'{attack_name}_{dataset_name}_mp{mask_pct}_nv{num_voter}_{defense}_log.csv',\n",
    "    checkpoint_interval=25, \n",
    "    checkpoint_dir=\"chkpts_2\", \n",
    "    disable_stdout=True\n",
    ")\n",
    "# Perform the attack and save the results\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()\n",
    "\n",
    "print(f'The above are results for {attack_name}_{dataset_name}_mp{mask_pct}_nv{num_voter}_{defense}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0926a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
